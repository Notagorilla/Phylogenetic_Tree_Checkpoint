{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os as os\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rpy2.robjects as ro\n",
    "import seaborn as sns\n",
    "\n",
    "from jax import random\n",
    "from jax import jit\n",
    "\n",
    "#import optax\n",
    "from numba import njit\n",
    "import numba as nb\n",
    "from numpy import genfromtxt\n",
    "\n",
    "jax.default_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "rooted = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True)\n",
    "def forward(W):\n",
    "    n_leaves = len(W) + 1\n",
    "    E = np.zeros((n_leaves, n_leaves), dtype=W.dtype)\n",
    "    E_new = np.zeros((n_leaves, n_leaves), dtype=W.dtype)\n",
    "    cache = np.zeros((n_leaves-1,n_leaves, n_leaves), dtype=W.dtype)\n",
    "    for i in range(1, n_leaves):\n",
    "        E_before_sub = E[:i, :i]\n",
    "        E_new.fill(0) \n",
    "        w_row_sub = W[i-1,:i]\n",
    "        for k in range(i):\n",
    "            for j in range(k):\n",
    "                E_new[k, j] = E_before_sub[k, j] * (1 - 0.5 * (w_row_sub[j] + w_row_sub[k]))\n",
    "            E_new[i, k] = 0.5 * np.sum(E_before_sub[:i, k] * w_row_sub) + 0.25 * w_row_sub[k]\n",
    "        E = E_new + E_new.T\n",
    "        cache[i-1,:i,:i] = E_before_sub\n",
    "\n",
    "    return E, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@njit(fastmath=True)\n",
    "def backward(W, D, cache):\n",
    "    dW = np.zeros_like(W)\n",
    "    dE = D.copy()\n",
    "    for j in range(cache.shape[0]-1, -1, -1):\n",
    "        i = j + 1\n",
    "        w_row_sub = W[i-1,:i]\n",
    "        E_before_sub = cache[j,:i,:i]\n",
    "        i_idx = i - 1\n",
    "        dE_new = dE + dE.T\n",
    "\n",
    "        dE_before_accum_sub = np.zeros_like(E_before_sub, dtype=W.dtype)\n",
    "\n",
    "        for k_ in range(i):\n",
    "            for j_ in range(k_):\n",
    "                dval = dE_new[k_, j_]\n",
    "                dW[i_idx, j_] += dval * (-0.5 * E_before_sub[k_, j_])\n",
    "                dW[i_idx, k_] += dval * (-0.5 * E_before_sub[k_, j_])\n",
    "                dE_before_accum_sub[k_, j_] += dval * (1 - 0.5*(w_row_sub[j_] + w_row_sub[k_]))\n",
    "\n",
    "        for k_ in range(i):\n",
    "            dval = dE_new[i, k_]\n",
    "            for m_ in range(i):\n",
    "                dW[i_idx, m_] += dval * (0.5 * E_before_sub[m_, k_])\n",
    "                dE_before_accum_sub[m_, k_] += dval * (0.5 * w_row_sub[m_])\n",
    "            dW[i_idx, k_] += dval * 0.25\n",
    "\n",
    "        dE[:i, :i] = dE_before_accum_sub\n",
    "        dE[i, :i] = 0  \n",
    "        dE[:i, i] = 0\n",
    "\n",
    "    return dW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our original tested jax function\n",
    "@jit\n",
    "def get_edges_exp(W,rooted=rooted):\n",
    "    n_leaves = len(W) + 1\n",
    "    E = jnp.zeros((n_leaves, n_leaves))\n",
    "\n",
    "    trindx_x, trindx_y = jnp.tril_indices(n_leaves-1, -1)\n",
    "    E = E.at[1, 0].set(0.5 * E[0, 0] * W[0, 0] + 0.25 * (2 - rooted) * W[0, 0])\n",
    "\n",
    "    E = E + jnp.transpose(E)\n",
    "\n",
    "    mask_E = jnp.ones_like(E)\n",
    "    mask_W = jnp.ones_like(W)\n",
    "\n",
    "    def body(carry, _):\n",
    "        E, i = carry\n",
    "\n",
    "        E_new = jnp.zeros((n_leaves, n_leaves))\n",
    "\n",
    "        trindx_x_i = jnp.where(trindx_x < i, trindx_x, 1)\n",
    "        trindx_y_i = jnp.where(trindx_x < i, trindx_y, 0)\n",
    "\n",
    "        indx = (trindx_x_i, trindx_y_i)\n",
    "\n",
    "        E_new = E_new.at[indx].set(\n",
    "            E[indx] * (1 - 0.5 * (W[i-1, indx[1]] + W[i-1, indx[0]]))\n",
    "        )\n",
    "\n",
    "        mask_Ei = jnp.where(jnp.arange(E.shape[0]) >= i, 0, mask_E)\n",
    "        mask_Eii = jnp.where(jnp.arange(E.shape[1]) >= i, 0, mask_Ei.T)\n",
    "\n",
    "        Eii = jnp.multiply(E, mask_Eii)\n",
    "\n",
    "        mask_Wii = jnp.where(jnp.arange(W.shape[1]) >= i, 0, mask_W[i-1])\n",
    "\n",
    "        Wii = jnp.multiply(W[i-1], mask_Wii)\n",
    "\n",
    "        tmp = 0.5 * jnp.sum(Eii[:n_leaves-1, :n_leaves-1] * Wii, 1) + 0.25 * Wii\n",
    "\n",
    "        E_new = E_new.at[i, :n_leaves-1].set(tmp)\n",
    "\n",
    "        E = E_new + jnp.transpose(E_new)\n",
    "\n",
    "        return (E, i+1), None\n",
    "\n",
    "\n",
    "    (E, _), _ = jax.lax.scan(body, (E, 2), None, length=n_leaves-2) \n",
    "\n",
    "    return E\n",
    "\n",
    "\n",
    "\n",
    "@jit\n",
    "def make_W(M):\n",
    "    k = int((1 +  math.sqrt(1+8*len(M)))//2) - 1\n",
    "\n",
    "    W = jnp.zeros((k, k)).at[\n",
    "        jnp.tril_indices(k)\n",
    "    ].set(jax.nn.relu(M))        \n",
    "\n",
    "    return W / jnp.tril(W).sum(1)[:, jnp.newaxis]\n",
    "\n",
    "@jit\n",
    "def bme_loss(W, D):\n",
    "    E = get_edges_exp(W)\n",
    "    return (D * E).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def forward_sqrtn_checkpoint(W):\n",
    "    \"\"\"\n",
    "    Compute the forward pass with square root checkpointing strategy.\n",
    "    \n",
    "    Args:\n",
    "        W: Upper triangular weight matrix of shape (n-1, n-1) where n is number of leaves\n",
    "        \n",
    "    Returns:\n",
    "        E: Final computed matrix of shape (n, n)\n",
    "        cache: Dictionary storing checkpointed states {iteration: submatrix}\n",
    "    \"\"\"\n",
    "    n_leaves = len(W) + 1  # Total number of leaf nodes\n",
    "    checkpoint_interval = max(1, int(np.sqrt(n_leaves - 1)))  # Checkpoint every sqrt(n) steps\n",
    "    E = np.zeros((n_leaves, n_leaves), dtype=W.dtype)  # Main computation matrix\n",
    "    E_new = np.zeros((n_leaves, n_leaves), dtype=W.dtype)  # Temporary matrix\n",
    "    cache = {}  # Dictionary to store checkpoints\n",
    "    \n",
    "    # Initial state (only leaf 0 exists)\n",
    "    cache[0] = np.zeros((1, 1), dtype=W.dtype)  # Store initial 1x1 zero matrix\n",
    "    E[:1, :1] = cache[0]  # Initialize E with first leaf\n",
    "\n",
    "    for i in range(1, n_leaves):\n",
    "        # Store checkpoint (state before adding leaf i)\n",
    "        if (i-1) % checkpoint_interval == 0:\n",
    "            cache[i-1] = E[:i, :i].copy()  # Save current state\n",
    "\n",
    "        # Computation steps for adding leaf i\n",
    "        E_before_sub = E[:i, :i]  # Previous state (leaves 0 to i-1)\n",
    "        E_new.fill(0)  # Reset temporary matrix\n",
    "        w_row_sub = W[i-1, :i]  # Weights for new connections\n",
    "\n",
    "        # Update off-diagonal elements\n",
    "        for k in range(i):\n",
    "            for j in range(k):\n",
    "                E_new[k, j] = E_before_sub[k, j] * (1 - 0.5 * (w_row_sub[j] + w_row_sub[k]))\n",
    "        \n",
    "        # Update new row/column for leaf i\n",
    "        for k in range(i):\n",
    "            E_new[i, k] = 0.5 * np.sum(E_before_sub[:i, k] * w_row_sub) + 0.25 * w_row_sub[k]\n",
    "\n",
    "        # Make symmetric and update E\n",
    "        E[:i+1, :i+1] = E_new[:i+1, :i+1] + E_new[:i+1, :i+1].T\n",
    "\n",
    "    # Store final state\n",
    "    cache[n_leaves-1] = E.copy()\n",
    "    return E, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True)\n",
    "def recompute_E_until(W, target_i, cache):\n",
    "    n_leaves = len(W) + 1\n",
    "    \n",
    "    # Special case for initial state (only leaf 0 exists)\n",
    "    if target_i == 0:\n",
    "        return cache[0]  # Returns (1,1) zero matrix\n",
    "    \n",
    "    E = np.zeros((n_leaves, n_leaves), dtype=W.dtype)\n",
    "    \n",
    "    # Find the latest checkpoint before target_i\n",
    "    last_ckpt_i = 0\n",
    "    for k in cache.keys():\n",
    "        if k < target_i and k > last_ckpt_i:\n",
    "            last_ckpt_i = k\n",
    "    \n",
    "    # Restore state from checkpoint\n",
    "    ckpt = cache[last_ckpt_i]\n",
    "    if last_ckpt_i == 0:\n",
    "        E[:1, :1] = ckpt  # Initialize first element\n",
    "    else:\n",
    "        # Copy the checkpointed submatrix\n",
    "        min_dim = min(ckpt.shape[0], E.shape[0])\n",
    "        E[:min_dim, :min_dim] = ckpt[:min_dim, :min_dim]\n",
    "    \n",
    "    # Forward compute from checkpoint to target_i\n",
    "    for i in range(last_ckpt_i + 1, target_i + 1):\n",
    "        if i >= n_leaves:\n",
    "            break\n",
    "            \n",
    "        E_new = np.zeros((n_leaves, n_leaves), dtype=W.dtype)\n",
    "        E_before_sub = E[:i, :i]  # Current state before adding leaf i\n",
    "        w_row_sub = W[i-1, :i]    # Connection weights for new leaf\n",
    "\n",
    "        # Update existing connections\n",
    "        for k in range(i):\n",
    "            for j in range(k):\n",
    "                E_new[k, j] = E_before_sub[k, j] * (1 - 0.5 * (w_row_sub[j] + w_row_sub[k]))\n",
    "        \n",
    "        # Add new connections for leaf i\n",
    "        for k in range(i):\n",
    "            E_new[i, k] = 0.5 * np.sum(E_before_sub[:i, k] * w_row_sub) + 0.25 * w_row_sub[k]\n",
    "\n",
    "        # Make symmetric and update E\n",
    "        E[:i+1, :i+1] = E_new[:i+1, :i+1] + E_new[:i+1, :i+1].T\n",
    "    \n",
    "    # Return the submatrix up to target_i\n",
    "    return E[:target_i+1, :target_i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True)\n",
    "def backward_sqrtn_checkpoint(W, D, cache):\n",
    "    n_leaves = len(W) + 1\n",
    "    dW = np.zeros_like(W)  # Gradient for weight matrix\n",
    "    dE = D.copy()  # Gradient of loss w.r.t. E matrix\n",
    "\n",
    "    # Precompute all checkpoint positions for faster lookup\n",
    "    checkpoint_indices = set(cache.keys())\n",
    "\n",
    "    # Backward pass through all leaves (reverse order)\n",
    "    for j in range(n_leaves - 2, -1, -1):  # j from n_leaves-2 down to 0\n",
    "        i = j + 1  # Current leaf index (1-based conversion)\n",
    "        i_idx = i - 1  # Corresponding row index in W (0-based)\n",
    "\n",
    "        # Retrieve or recompute the state before adding leaf i\n",
    "        if (i-1) in checkpoint_indices:  # Check if checkpoint exists\n",
    "            E_before_sub = cache[i-1]  # Use stored checkpoint\n",
    "        else:\n",
    "            E_before_sub = recompute_E_until(W, i-1, cache)  # Recompute from nearest checkpoint\n",
    "\n",
    "        w_row_sub = W[i_idx, :i]  # Connection weights for current leaf\n",
    "        dE_new = dE + dE.T  # Symmetrize gradient\n",
    "        dE_before_accum_sub = np.zeros_like(E_before_sub, dtype=W.dtype)  # Accumulator\n",
    "\n",
    "        # First gradient term: off-diagonal elements\n",
    "        for k_ in range(i):\n",
    "            for j_ in range(k_):\n",
    "                dval = dE_new[k_, j_]  # Current gradient value\n",
    "                # Update weight gradients\n",
    "                dW[i_idx, j_] += dval * (-0.5 * E_before_sub[k_, j_])\n",
    "                dW[i_idx, k_] += dval * (-0.5 * E_before_sub[k_, j_])\n",
    "                # Accumulate gradient for next step\n",
    "                dE_before_accum_sub[k_, j_] += dval * (1 - 0.5 * (w_row_sub[j_] + w_row_sub[k_]))\n",
    "\n",
    "        # Second gradient term: new row/column elements\n",
    "        for k_ in range(i):\n",
    "            dval = dE_new[i, k_]  # Gradient for new connections\n",
    "            for m_ in range(i):\n",
    "                # Update weight gradients\n",
    "                dW[i_idx, m_] += dval * (0.5 * E_before_sub[m_, k_])\n",
    "                # Accumulate gradient for next step\n",
    "                dE_before_accum_sub[m_, k_] += dval * (0.5 * w_row_sub[m_])\n",
    "            # Additional weight gradient term\n",
    "            dW[i_idx, k_] += dval * 0.25\n",
    "\n",
    "        # Update gradient for next iteration\n",
    "        dE[:i, :i] = dE_before_accum_sub  # Propagate gradient backward\n",
    "        dE[i, :i] = 0  # Reset gradients\n",
    "        dE[:i, i] = 0  # Reset gradients\n",
    "\n",
    "    return dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_num = 200\n",
    "params =  jnp.array(np.random.rand(round(0.5 * v_num * (v_num - 1))) * 0.5)\n",
    "M=params\n",
    "k = int((1 +  math.sqrt(1+8*len(M)))//2) - 1\n",
    "D = jnp.array(np.random.rand(v_num,v_num)*(1-np.eye(v_num)))\n",
    "D=0.5*(D+D.T)\n",
    "W = make_W(M)  \n",
    "#W = jnp.array(np.eye(W.shape[0])[W.argmax(1)])\n",
    "\n",
    "value_and_grad_fun = jax.jit(jax.value_and_grad(bme_loss, argnums=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E2, cache = forward_sqrtn_checkpoint(np.array(W))\n",
    "g2 = backward_sqrtn_checkpoint(np.array(W), np.array(D), cache)\n",
    "E = get_edges_exp(W, rooted)\n",
    "v, g = value_and_grad_fun(W, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle('Get edges and Gradient')\n",
    "axs[0].plot(E - E2,'.');\n",
    "axs[1].plot(g - g2,'.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
